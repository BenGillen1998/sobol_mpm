{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d431565",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23b1c",
   "metadata": {},
   "source": [
    "# Sobol' Indices Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5686d8",
   "metadata": {},
   "source": [
    "## What are Sobol' Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10fd4c",
   "metadata": {},
   "source": [
    "Sobol' indices are a way to quantify the variance that random variables have on the output of a model. The 'best' way to use Sobol' indices is when you have a good understanding of the distributions of your input variables. Specifically, you want your inputs to come from 'nice' distributions. I am still figuring out these heuristics, but Heijungs 2024 seems to have some good ideas. He classifies Sobol' indices as 'uncertainty apportioning' (as opposed to uncertainty quantification or sensitivity analysis), which stuy the subdivision of output uncertainties in terms of the contributions by input uncertainties (see p. 695). Heijungs presents Morris's Elementary Effects as global UQ, but I am at this time unconvinced that it is in any way more useful than Sobol' indices. I need to examine it more though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3ada6",
   "metadata": {},
   "source": [
    "## First Order Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7b480",
   "metadata": {},
   "source": [
    "We can consider our output variable $Y$ to be some function of our input variables.\n",
    "$$Y = f(X_1, X_2, ..., X_k)$$\n",
    "Each input is a random variable. We can then decompose $f$ into terms of increasing dimension. Take $f_{ij} = f(X_i,X_j)$. Then,\n",
    "$$f = f_0 = \\sum_i f_i + \\sum_{i<j}f_{ij} + ... + f_{12...k}$$\n",
    "Sobol' proved that if each term in the above expansion has zero mean (e.g. $E[f_{247}] = 0$), then all the terms are orthogonal in pairs $E[f_if_j] = 0$. Note that if any function in your decomposition has non-zero mean $f_i = \\mu$, you can build a new decomposition as follows:\n",
    "$$f = (f_0 + \\mu) + ... + (f_i - \\mu) + ... = \\tilde{f}_0 + ... + \\tilde{f}_i + ...$$\n",
    "with $E[\\tilde{f}_i] = 0$. From the above, we can find the variances (written as $V$ here) of the decomposition terms. Starting with the first order terms:\n",
    "$$E[Y | X_i] = f_0 + f_i = E[Y] + f_i$$\n",
    "and so\n",
    "$$V(f_i) = V(E[Y | X_i])$$\n",
    "Divide by the unconditional variance to get the first order Sobol' indices.\n",
    "$$S_i = \\frac{V(E[Y | X_i])}{V(Y)}$$\n",
    "Note that this term specifically gives us the variance from the $X_i$ function. Therefore, if $X_i$ is part of a higher order function (e.g. $f_{ij}$), the variance from that function will not be included in this Sobol' index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eca0c7",
   "metadata": {},
   "source": [
    "## Higher Order Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef433b83",
   "metadata": {},
   "source": [
    " To get the higher order indices, we use a similar method. We must make sure we subtract off the variances we have already calculated.\n",
    "$$V_{ij} = V\\bigl(f_{ij}(X_i, X_j)\\bigr) = V\\bigl(\\mathbb{E}[Y\\mid X_i, X_j]\\bigr)- V\\bigl(\\mathbb{E}[Y\\mid X_i]\\bigr)- V\\bigl(\\mathbb{E}[Y\\mid X_j]\\bigr)$$\n",
    "Higher order terms follow in a similar fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554a2d9",
   "metadata": {},
   "source": [
    "## Total Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad37ce8",
   "metadata": {},
   "source": [
    "Higher order indices often do not offer much in terms of explanatory power while demanding a large amount of computation. Therefore, total effects are employed to get the full of variance from each $X_i$ (i.e. the sum of its first order and higher order effects). The total effect of $X_1$ from $f(X_1,X_2,X_3)$ is given by\n",
    "$$ S_{T1} = S_1 + S_{12} + S_{13} + S_{123} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414b2ea",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbbbdb",
   "metadata": {},
   "source": [
    "The standard computation of Sobol' indices uses a pseudo Monte-Carlo simulation. Build 2 matrices of $(N,k)$ dimension. Here, $N$ is (half) the number of samples you wish to generate, and $k$ is the length of our function $f$ (i.e. the number of input variables). Then, build $k$ matricies $C_i$ by replacing the $i$'th column of $B$ with the $i$'th column of $A$. Calculate the output for each row to build an output vector for each matrix. The first order indices are therefore calculated as follows.\n",
    "\n",
    "$$ S_i \\;=\\; \\frac{V\\bigl[\\mathbb{E}(Y\\mid X_i)\\bigr]}{V(Y)}\n",
    "\\;=\\;\n",
    "\\frac{y_A\\cdot y_{C_i} \\;-\\; f_0^2}{\\,y_A\\cdot y_A \\;-\\; f_0^2\\,} $$\n",
    "\n",
    "The total order indices are straightforwadly calculated as well.\n",
    "\n",
    "$$ S_{T_i}\n",
    "\\;=\\;\n",
    "1 \\;-\\; \\frac{V\\bigl[\\mathbb{E}(Y\\mid X_{\\sim i})\\bigr]}{V(Y)}\n",
    "\\;=\\;\n",
    "1 \\;-\\; \\frac{y_B \\cdot y_{C_i} \\;-\\; f_0^2}{\\,y_A \\cdot y_A \\;-\\; f_0^2\\,}$$\n",
    "\n",
    "Here is explicity what the $A, B, C_i$ matrices look like. Note that $B$ uses a sample from $k+1$ to $2k$; however, this is just for notational simplicity. Matrix $B$ is from the exact same sample space as matrix $A$.\n",
    "\n",
    "$$A = \n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_{1} & x^{(1)}_{2} & \\cdots & x^{(1)}_{i} & \\cdots & x^{(1)}_{k} \\\\\n",
    "x^{(2)}_{1} & x^{(2)}_{2} & \\cdots & x^{(2)}_{i} & \\cdots & x^{(2)}_{k} \\\\\n",
    "\\vdots      & \\vdots      & \\ddots & \\vdots      &        & \\vdots      \\\\\n",
    "x^{(N)}_{1} & x^{(N)}_{2} & \\cdots & x^{(N)}_{i} & \\cdots & x^{(N)}_{k}\n",
    "\\end{bmatrix}, \\quad\n",
    "B = \n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_{k+1} & x^{(1)}_{k+2} & \\cdots & x^{(1)}_{k+i} & \\cdots & x^{(1)}_{2k} \\\\\n",
    "x^{(2)}_{k+1} & x^{(2)}_{k+2} & \\cdots & x^{(2)}_{k+i} & \\cdots & x^{(2)}_{2k} \\\\\n",
    "\\vdots        & \\vdots        & \\ddots & \\vdots        &        & \\vdots        \\\\\n",
    "x^{(N)}_{k+1} & x^{(N)}_{k+2} & \\cdots & x^{(N)}_{k+i} & \\cdots & x^{(N)}_{2k}\n",
    "\\end{bmatrix},$$\n",
    "$$ C_i = \n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_{k+1} & x^{(1)}_{k+2} & \\cdots & x^{(1)}_{i} & \\cdots & x^{(1)}_{2k} \\\\\n",
    "x^{(2)}_{k+1} & x^{(2)}_{k+2} & \\cdots & x^{(2)}_{i} & \\cdots & x^{(2)}_{2k} \\\\\n",
    "\\vdots        & \\vdots        & \\ddots & \\vdots      &        & \\vdots        \\\\\n",
    "x^{(N)}_{k+1} & x^{(N)}_{k+2} & \\cdots & x^{(N)}_{i} & \\cdots & x^{(N)}_{2k}\n",
    "\\end{bmatrix} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
